{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mutual_info_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All the pre-processing and cleaning\n",
    "\"\"\"\n",
    "\n",
    "df.TotalCharges = pd.to_numeric(df.TotalCharges, errors ='coerce')        #coerce -> replace all nonnumeric values with NaN\n",
    "df.TotalCharges = df.TotalCharges.fillna(0)\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "string_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "numerical = ['tenure','monthlycharges', 'totalcharges']\n",
    "categorical = [ 'gender', 'seniorcitizen', 'partner', 'dependents',\n",
    "       'phoneservice', 'multiplelines', 'internetservice',\n",
    "       'onlinesecurity', 'onlinebackup', 'deviceprotection', 'techsupport',\n",
    "       'streamingtv', 'streamingmovies', 'contract', 'paperlessbilling',\n",
    "       'paymentmethod']\n",
    "\n",
    "for col in string_columns:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "\n",
    "# now spliting it in train and validation\n",
    "df_train, df_val = train_test_split(df_train_full, test_size= 0.33, random_state= 11)\n",
    "\n",
    "y_train = df_train.churn.values\n",
    "y_val = df_val.churn.values\n",
    "\n",
    "\n",
    "del df_train['churn']\n",
    "del df_val['churn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df,y,C):                                                      #We add C to the parameters\n",
    "    cat = df[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    dv.fit(cat)\n",
    "\n",
    "    X = dv.transform(cat)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=C)                 #which we use for the training \n",
    "    model.fit(X,y)\n",
    "\n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "    cat = df[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(cat)\n",
    "    y_pred = model.predict_proba(X)[:,1]\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(customer, dv,model):\n",
    "    X = dv.transform([customer])\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    return y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.001, auc = 0.825 ± 0.013\n",
      "C=0.01, auc = 0.839 ± 0.009\n",
      "C=0.1, auc = 0.841 ± 0.008\n",
      "C=0.5, auc = 0.841 ± 0.007\n",
      "C=1, auc = 0.841 ± 0.007\n",
      "C=10, auc = 0.841 ± 0.007\n"
     ]
    }
   ],
   "source": [
    "#We loop over different values of C,\n",
    "#For each C we run cross-validation and record the mean AUC accross all folds as weel as standard deviation\n",
    "\n",
    "nfolds = 5\n",
    "kfold = KFold(n_splits=nfolds, shuffle=True, random_state=1)    #split the dataset in 10 parts\n",
    "for C in [0.001, 0.01, 0.1, 0.5, 1, 10]:\n",
    "    aucs = []                                                   #to add the auc scores\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(df_train_full):       # to iterate over the 10 parts\n",
    "        df_train = df_train_full.iloc[train_idx]                #split the data into train and validation\n",
    "        df_val = df_train_full.iloc[val_idx]\n",
    "\n",
    "        y_train = df_train.churn.values\n",
    "        y_val = df_val.churn.values\n",
    "\n",
    "        dv, model = train(df_train, y_train, C)                    #trains the models and make predictions\n",
    "        y_pred = predict(df_val, dv, model)\n",
    "\n",
    "        auc = roc_auc_score(y_val, y_pred)                      #evaluates the quality of the model \n",
    "        aucs.append(auc)\n",
    "    print('C=%s, auc = %0.3f ± %0.3f' % (C, np.mean(aucs), np.std(aucs)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc = 0.859\n"
     ]
    }
   ],
   "source": [
    "# AUC of the model, 85.9% accuracy\n",
    "\n",
    "y_train = df_train_full.churn.values\n",
    "y_test = df_test.churn.values\n",
    "\n",
    "dv, model = train(df_train_full, y_train, C=0.5)\n",
    "y_pred = predict(df_test, dv, model)\n",
    "\n",
    "auc= roc_auc_score(y_test, y_pred)\n",
    "print('auc = %.3f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Saving the model to use it externally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('churn-model.bin', 'wb') as f_out:\n",
    "    pickle.dump((dv, model),f_out)\n",
    "\n",
    "f_out = open('churn-model.bin', 'wb')\n",
    "pickle.dump((dv,model), f_out)\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
